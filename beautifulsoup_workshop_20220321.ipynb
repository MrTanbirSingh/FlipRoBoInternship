{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d6d063",
   "metadata": {},
   "source": [
    "## Scrape Data with Beautiful Soup & Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68017112",
   "metadata": {},
   "source": [
    "#### **WEB SCRAPING**\n",
    "In all the following questions, you have to use BeautifulSoup to scrape different websites and collect data as per\n",
    "the requirement of the question.\n",
    "Every answer to the question should be in form of a python function which should take URL as the parameter.\n",
    "Use Jupyter Notebooks to program, upload it on your GitHub and send the link of the Jupyter notebook to\n",
    "your SME.\n",
    "\n",
    "\n",
    "1) Display all the header tags from wikipedia.org.<br>\n",
    "\n",
    "2) Display IMDB’s Top rated 100 movies’ data. <br>\n",
    "\n",
    "3) Display IMDB’s Top rated 100 Indian movies’ data. <br>\n",
    "\n",
    "4) Scrape product from **https://meesho.com/bagsladies/pl/p7vbp** <br>\n",
    "    \n",
    "5) Scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "and the code for the video from the link for the youtube video from the post.\n",
    "\n",
    "8) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "area, EMI and price .Enter three localities which are Indira Nagar, Jayanagar,\n",
    "Rajaji Nagar.<br>\n",
    "url = \"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar\"\n",
    "\n",
    "\n",
    "9) Write a python program to scrape mentioned details from https://dineout.co.in :\n",
    "**i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL**\n",
    "\n",
    "10) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/women-printed-t-shirts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0777b844",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91a5d0",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdcae6",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed96bc",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "928531ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def header(url, tag1, tag2):\n",
    "    soup = BeautifulSoup(requests.get(url).content)\n",
    "    [print(i.text) for i in soup.find_all(tag1)], [print(i.text) for i in soup.find_all(tag2)]\n",
    "\n",
    "header(url = 'https://en.wikipedia.org/wiki/Main_Page', tag1 = 'h1', tag2 = 'h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4184cdb",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb48e8",
   "metadata": {},
   "source": [
    " **-------------------------------------------------------------------------------------------------------------------------** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd9821",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261434d6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28d037",
   "metadata": {},
   "source": [
    "### 2) IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "c427d3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>name</th>\n",
       "      <th>release</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Jagten</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Vertigo</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no                                 name release ratings\n",
       "0     1             The Shawshank Redemption  (1994)     9.2\n",
       "1     2                        The Godfather  (1972)     9.2\n",
       "2     3                      The Dark Knight  (2008)     9.0\n",
       "3     4               The Godfather: Part II  (1974)     9.0\n",
       "4     5                         12 Angry Men  (1957)     9.0\n",
       "..  ...                                  ...     ...     ...\n",
       "95   96    M - Eine Stadt sucht einen Mörder  (1931)     8.3\n",
       "96   97                   North by Northwest  (1959)     8.3\n",
       "97   98                               Jagten  (2012)     8.3\n",
       "98   99                              Vertigo  (1958)     8.3\n",
       "99  100  Le fabuleux destin d'Amélie Poulain  (2001)     8.3\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def imdb_top_100( url, filter_range):\n",
    "    \n",
    "    imdb_soup = BeautifulSoup(requests.get( url ).content)\n",
    "    imdb_name_release = imdb_soup.find_all('td',class_ = \"titleColumn\")\n",
    "\n",
    "    counts = []\n",
    "    movienames = []\n",
    "    release_year = []\n",
    "    ratings = []\n",
    "\n",
    "    #count\n",
    "    for num in imdb_soup.find_all('td',class_ = \"titleColumn\"):\n",
    "        counts.append(int(num.text.split()[0].replace(\".\",'')))\n",
    "    #Movie_Names\n",
    "    for name in imdb_soup.find_all('td',class_ = \"titleColumn\"):\n",
    "        movienames.append(name.find('a').text)\n",
    "    #Release_Year\n",
    "    for year in imdb_soup.find_all('span', class_ = \"secondaryInfo\"):\n",
    "        release_year.append(year.text)\n",
    "    #Rating\n",
    "    for rating in imdb_soup.find_all('td', class_ =\"ratingColumn imdbRating\"):\n",
    "        ratings.append(rating.text.replace('\\n',''))\n",
    "    \n",
    "    imdb_top_movies = pd.DataFrame({'no': counts, 'name': movienames, 'release': release_year, 'ratings': ratings})\n",
    "    \n",
    "    #print(imdb_top_movies[imdb_top_movies['no'] <= filter_range])\n",
    "    return imdb_top_movies.head(filter_range)\n",
    "    \n",
    "imdb_top_100(url = 'https://www.imdb.com/chart/top', filter_range = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b83286",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a1d15",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c4c194",
   "metadata": {},
   "source": [
    " **-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b05ad",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d2bc1",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b95eb4",
   "metadata": {},
   "source": [
    "### 3) IMDB’s Top rated 100 Indian movies (name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "4d2a3d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>name</th>\n",
       "      <th>release</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Golmaal</td>\n",
       "      <td>(1979)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>The Legend of Bhagat Singh</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Sholay</td>\n",
       "      <td>(1975)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Angoor</td>\n",
       "      <td>(1982)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Maheshinte Prathikaaram</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no                         name release ratings\n",
       "0     1                     Jai Bhim  (2021)     8.4\n",
       "1     2                   Anbe Sivam  (2003)     8.4\n",
       "2     3            Pariyerum Perumal  (2018)     8.4\n",
       "3     4                      Golmaal  (1979)     8.4\n",
       "4     5                      Nayakan  (1987)     8.4\n",
       "..  ...                          ...     ...     ...\n",
       "95   96   The Legend of Bhagat Singh  (2002)     8.0\n",
       "96   97                       Sholay  (1975)     8.0\n",
       "97   98                       Angoor  (1982)     8.0\n",
       "98   99  Baahubali 2: The Conclusion  (2017)     8.0\n",
       "99  100      Maheshinte Prathikaaram  (2016)     8.0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def imdb_top_100( url, filter_range):\n",
    "    \n",
    "    imdb_soup = BeautifulSoup(requests.get( url ).content)\n",
    "    imdb_name_release = imdb_soup.find_all('td',class_ = \"titleColumn\")\n",
    "\n",
    "    counts = []\n",
    "    movienames = []\n",
    "    release_year = []\n",
    "    ratings = []\n",
    "\n",
    "    #count\n",
    "    for num in imdb_soup.find_all('td',class_ = \"titleColumn\"):\n",
    "        counts.append(int(num.text.split()[0].replace(\".\",'')))\n",
    "    #Movie_Names\n",
    "    for name in imdb_soup.find_all('td',class_ = \"titleColumn\"):\n",
    "        movienames.append(name.find('a').text)\n",
    "    #Release_Year\n",
    "    for year in imdb_soup.find_all('span', class_ = \"secondaryInfo\"):\n",
    "        release_year.append(year.text)\n",
    "    #Rating\n",
    "    for rating in imdb_soup.find_all('td', class_ =\"ratingColumn imdbRating\"):\n",
    "        ratings.append(rating.text.replace('\\n',''))\n",
    "    \n",
    "    imdb_top_movies = pd.DataFrame({'no': counts, 'name': movienames, 'release': release_year, 'ratings': ratings})\n",
    "    \n",
    "    #print(imdb_top_movies[imdb_top_movies['no'] <= filter_range])\n",
    "    return imdb_top_movies.head(filter_range)\n",
    "    \n",
    "imdb_top_100(url = 'https://www.imdb.com/india/top-rated-indian-movies/', filter_range = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b150f4",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef550c9",
   "metadata": {},
   "source": [
    " **-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f418c3",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169db41",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76433880",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63145a54",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bagsladies/pl/p7vbp ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "61562367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>discount</th>\n",
       "      <th>discount_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graceful Fashionable Women Handbags</td>\n",
       "      <td>620</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classic Attractive Women Handbags</td>\n",
       "      <td>584</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voguish Alluring Women Handbags</td>\n",
       "      <td>284</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Classic Fashionable Women Handbags</td>\n",
       "      <td>990</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FashionableLatest Women  handbag</td>\n",
       "      <td>100</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fancy Modern Women Handbag</td>\n",
       "      <td>1442</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elite Fashionable Women Handbags</td>\n",
       "      <td>1399</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graceful Alluring Women Handbags</td>\n",
       "      <td>484</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Collections Of Garbage Handbags</td>\n",
       "      <td>784</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Classic Versatile Women Handbags</td>\n",
       "      <td>710</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Handbags</td>\n",
       "      <td>8999</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>8949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Graceful Attractive Women Handbags</td>\n",
       "      <td>500</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Graceful Women Women Handbags</td>\n",
       "      <td>334</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Styles Latest Women handbags</td>\n",
       "      <td>1169</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Attractive Handbags</td>\n",
       "      <td>531</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fashionable Women Handbag</td>\n",
       "      <td>354</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Classic Versatile Women Handbags</td>\n",
       "      <td>799</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Classic Versatile Women Handbags</td>\n",
       "      <td>314</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ravishing Classy Women Handbags</td>\n",
       "      <td>616</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gorgeous Fancy Women Handbags</td>\n",
       "      <td>699</td>\n",
       "      <td>discount on 1st order</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            product_name product_price               discount  \\\n",
       "0    Graceful Fashionable Women Handbags           620  discount on 1st order   \n",
       "1      Classic Attractive Women Handbags           584  discount on 1st order   \n",
       "2        Voguish Alluring Women Handbags           284  discount on 1st order   \n",
       "3     Classic Fashionable Women Handbags           990  discount on 1st order   \n",
       "4       FashionableLatest Women  handbag           100  discount on 1st order   \n",
       "5             Fancy Modern Women Handbag          1442  discount on 1st order   \n",
       "6       Elite Fashionable Women Handbags          1399  discount on 1st order   \n",
       "7       Graceful Alluring Women Handbags           484  discount on 1st order   \n",
       "8    New Collections Of Garbage Handbags           784  discount on 1st order   \n",
       "9       Classic Versatile Women Handbags           710  discount on 1st order   \n",
       "10                              Handbags          8999  discount on 1st order   \n",
       "11    Graceful Attractive Women Handbags           500  discount on 1st order   \n",
       "12        Graceful Women Women Handbags            334  discount on 1st order   \n",
       "13          Styles Latest Women handbags          1169  discount on 1st order   \n",
       "14                   Attractive Handbags           531  discount on 1st order   \n",
       "15             Fashionable Women Handbag           354  discount on 1st order   \n",
       "16      Classic Versatile Women Handbags           799  discount on 1st order   \n",
       "17      Classic Versatile Women Handbags           314  discount on 1st order   \n",
       "18       Ravishing Classy Women Handbags           616  discount on 1st order   \n",
       "19         Gorgeous Fancy Women Handbags           699  discount on 1st order   \n",
       "\n",
       "   discount_price  \n",
       "0             570  \n",
       "1             534  \n",
       "2             242  \n",
       "3             940  \n",
       "4              85  \n",
       "5            1392  \n",
       "6            1349  \n",
       "7             434  \n",
       "8             734  \n",
       "9             660  \n",
       "10           8949  \n",
       "11            450  \n",
       "12            284  \n",
       "13           1119  \n",
       "14            481  \n",
       "15            304  \n",
       "16            749  \n",
       "17            267  \n",
       "18            566  \n",
       "19            649  "
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def shopping():\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(\"https://meesho.com/bagsladies/pl/p7vbp\").content)\n",
    "\n",
    "    names = []\n",
    "    product_prices = []\n",
    "    discount_msg = []\n",
    "    discount = []\n",
    "    \n",
    "    #Names\n",
    "    for data in soup.find_all('p', class_=\"Text__StyledText-sc-oo0kvp-0 cPgaBh NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw\"):\n",
    "        names.append(data.text)\n",
    "    \n",
    "    #PRODUCT PRICES\n",
    "    for prices in soup.find_all('p', class_ =\"Text__StyledText-sc-oo0kvp-0 hgHnkG Paragraph__StyledParagraphBody2StrikeThrough-sc-69qp0d-0 coIjqc Paragraph__StyledParagraphBody2StrikeThrough-sc-69qp0d-0 coIjqc\"):\n",
    "        product_prices.append(prices.text.replace('₹',''))\n",
    "       \n",
    "        \n",
    "    #Discount\n",
    "    for discont in soup.find_all('h5', class_ =\"Text__StyledText-sc-oo0kvp-0 dLSsNI\"):\n",
    "        discount.append(discont.text.split()[0].replace('₹', ''))\n",
    "        \n",
    "    #Discount_msg\n",
    "    for discont_msg in soup.find_all('p', class_ =\"Text__StyledText-sc-oo0kvp-0 iDRzyZ NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 dppwvY NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 dppwvY\"):\n",
    "        discount_msg.append(' '.join(discont_msg.text.split()[1:]))\n",
    "        \n",
    "    df_shopping = pd.DataFrame({'product_name':names, 'product_price':product_prices, 'discount':discount_msg, 'discount_price': discount})\n",
    "    \n",
    "    return df_shopping\n",
    "\n",
    "shopping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0d2cb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db9290",
   "metadata": {},
   "source": [
    " **-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54342c39",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9235ce",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1fe211",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612449ca",
   "metadata": {},
   "source": [
    "### 5) Write a python program to scrape cricket rankings from icc-cricket.com.\n",
    "**a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.** <br>\n",
    "**b) Top 10 ODI Batsmen along with the records of their team and rating.** <br>\n",
    "**c) Top 10 ODI bowlers along with the records of their team and rating.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993ff11",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "bfaae4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_name</th>\n",
       "      <th>matches</th>\n",
       "      <th>rating</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>2,316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>119</td>\n",
       "      <td>3,793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>31</td>\n",
       "      <td>112</td>\n",
       "      <td>3,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>38</td>\n",
       "      <td>110</td>\n",
       "      <td>4,162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>31</td>\n",
       "      <td>102</td>\n",
       "      <td>3,167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>2,921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>36</td>\n",
       "      <td>93</td>\n",
       "      <td>3,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>35</td>\n",
       "      <td>81</td>\n",
       "      <td>2,835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "      <td>2,788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>1,562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>1,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UAE</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Oman</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Namibia</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>United States</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team_name matches rating points\n",
       "0        New Zealand      19    122  2,316\n",
       "1            England      32    119  3,793\n",
       "2          Australia      31    112  3,475\n",
       "3              India      38    110  4,162\n",
       "4       South Africa      31    102  3,167\n",
       "5           Pakistan      30     97  2,921\n",
       "6         Bangladesh      36     93  3,350\n",
       "7          Sri Lanka      35     81  2,835\n",
       "8        West Indies      36     77  2,788\n",
       "9        Afghanistan      23     68  1,562\n",
       "10           Ireland      28     52  1,445\n",
       "11          Scotland      10     45    452\n",
       "12          Zimbabwe      23     41    951\n",
       "13       Netherlands      12     36    433\n",
       "14               UAE      20     33    651\n",
       "15              Oman      24     30    720\n",
       "16           Namibia      13     21    268\n",
       "17             Nepal      17     18    308\n",
       "18     United States      14     17    232\n",
       "19  Papua New Guinea      19     11    207"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def men_odi_cricket_team():\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    team_name = [name.next.next.next.next.text for name in soup.find_all('td', class_=\"table-body__cell rankings-table__team\")]\n",
    "    team_name.insert(0,soup.find_all('span', class_=\"flag-30 rankings-block__banner--flag NZ\")[0].next.next.text)\n",
    "\n",
    "    matches = [country_name.text for country_name in soup.find_all('td', class_=\"table-body__cell u-center-text\")][0::2]\n",
    "    matches.insert(0, soup.find('td', class_=\"rankings-block__banner--matches\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    points = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell u-center-text\")][1::2]\n",
    "    points.insert(0, soup.find('td', class_=\"rankings-block__banner--points\").text.replace('\\n', '').replace('  ', ''))\n",
    "\n",
    "    rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right rating\")]\n",
    "    rating.insert(0, soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n', '').replace('  ', ''))\n",
    "     \n",
    "    print(len(team_name),len(matches),len(points),len(rating))\n",
    "    \n",
    "    df_mens_odi = pd.DataFrame({'team_name':team_name, 'matches':matches, 'rating':rating, 'points':points})\n",
    "    return df_mens_odi\n",
    "\n",
    "#Enter value to check top playes\n",
    "men_odi_cricket_team()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037499ce",
   "metadata": {},
   "source": [
    "### b)Top 10 ODI Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "149d25c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>career_best_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>872</td>\n",
       "      <td>873 v England, 13/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "      <td>911 v England, 12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>794</td>\n",
       "      <td>841 v Bangladesh, 05/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "      <td>885 v Sri Lanka, 06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "      <td>813 v Sri Lanka, 10/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "      <td>796 v India, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>771</td>\n",
       "      <td>798 v England, 25/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "      <td>776 v Bangladesh, 20/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>758</td>\n",
       "      <td>880 v Pakistan, 26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>746</td>\n",
       "      <td>768 v South Africa, 02/04/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             player_name country rating              career_best_rating\n",
       "0             Babar Azam     PAK    872       873 v England, 13/07/2021\n",
       "1            Virat Kohli     IND    811       911 v England, 12/07/2018\n",
       "2            Ross Taylor      NZ    794    841 v Bangladesh, 05/06/2019\n",
       "3           Rohit Sharma     IND    791     885 v Sri Lanka, 06/07/2019\n",
       "4        Quinton de Kock      SA    789     813 v Sri Lanka, 10/03/2019\n",
       "5         Jonny Bairstow     ENG    775         796 v India, 26/03/2021\n",
       "6            Aaron Finch     AUS    771       798 v England, 25/06/2019\n",
       "7  Rassie van der Dussen      SA    769    776 v Bangladesh, 20/03/2022\n",
       "8           David Warner     AUS    758      880 v Pakistan, 26/01/2017\n",
       "9            Imam-ul-Haq     PAK    746  768 v South Africa, 02/04/2021"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def men_odi_cricket(filter_result):\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    player_name = [name.text.replace('\\n', '') for name in soup.find_all('td', class_ =\"table-body__cell rankings-table__name name\")]\n",
    "    player_name.insert(0,soup.find('div', class_ =\"rankings-block__banner--name-large\").text)\n",
    "    \n",
    "    country = [country_name.text for country_name in soup.find_all('span', class_=\"table-body__logo-text\")]\n",
    "    country.insert(0, soup.find('div', class_ =\"rankings-block__banner--nationality\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    rating = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell rating\")]\n",
    "    rating.insert(0, soup.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    career_best_rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right u-hide-phablet\")]\n",
    "    career_best_rating.insert(0, soup.find('div',class_=\"rankings-block__career-best\").text.replace('\\n', '').replace('  ', ''))\n",
    "    \n",
    "    \n",
    "    df_mens_odi = pd.DataFrame({'player_name':player_name, 'country':country, 'rating':rating, 'career_best_rating':career_best_rating})\n",
    "    return df_mens_odi[df_mens_odi.index < filter_result]\n",
    "\n",
    "#Enter value to check top playes\n",
    "men_odi_cricket(filter_result= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58810390",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e9952",
   "metadata": {},
   "source": [
    "### c) Top 10 ODI bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "2a615800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>career_best_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>733</td>\n",
       "      <td>770 v West Indies, 22/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "      <td>711 v Sri Lanka, 04/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>687</td>\n",
       "      <td>691 v Bangladesh, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "      <td>712 v Ireland, 24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "      <td>841 v West Indies, 01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>661</td>\n",
       "      <td>725 v Sri Lanka, 25/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>657</td>\n",
       "      <td>717 v Zimbabwe, 05/11/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>650</td>\n",
       "      <td>650 v Pakistan, 29/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "      <td>806 v Pakistan, 21/09/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        player_name country rating             career_best_rating\n",
       "0       Trent Boult      NZ    733  770 v West Indies, 22/06/2019\n",
       "1    Josh Hazlewood     AUS    705      733 v England, 26/01/2018\n",
       "2      Chris Woakes     ENG    700    711 v Sri Lanka, 04/07/2021\n",
       "3        Matt Henry      NZ    687   691 v Bangladesh, 26/03/2021\n",
       "4  Mujeeb Ur Rahman     AFG    681      712 v Ireland, 24/01/2021\n",
       "5    Jasprit Bumrah     IND    679  841 v West Indies, 01/11/2018\n",
       "6      Mehedi Hasan     BAN    661    725 v Sri Lanka, 25/05/2021\n",
       "7   Shakib Al Hasan     BAN    657     717 v Zimbabwe, 05/11/2009\n",
       "8        Adam Zampa     AUS    650     650 v Pakistan, 29/03/2022\n",
       "9       Rashid Khan     AFG    650     806 v Pakistan, 21/09/2018"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def men_odi_cricket(filter_result):\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    player_name = [name.text.replace('\\n', '') for name in soup.find_all('td', class_ =\"table-body__cell rankings-table__name name\")]\n",
    "    player_name.insert(0,soup.find('div', class_ =\"rankings-block__banner--name-large\").text)\n",
    "    \n",
    "    country = [country_name.text for country_name in soup.find_all('span', class_=\"table-body__logo-text\")]\n",
    "    country.insert(0, soup.find('div', class_ =\"rankings-block__banner--nationality\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    rating = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell rating\")]\n",
    "    rating.insert(0, soup.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    career_best_rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right u-hide-phablet\")]\n",
    "    career_best_rating.insert(0, soup.find('div',class_=\"rankings-block__career-best\").text.replace('\\n', '').replace('  ', ''))\n",
    "    \n",
    "    \n",
    "    df_mens_odi = pd.DataFrame({'player_name':player_name, 'country':country, 'rating':rating, 'career_best_rating':career_best_rating})\n",
    "    return df_mens_odi[df_mens_odi.index < filter_result]\n",
    "\n",
    "#Enter value to check top playes\n",
    "men_odi_cricket(filter_result= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c56fd",
   "metadata": {},
   "source": [
    " **-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5b532",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e51853",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a6e31",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b217cb8",
   "metadata": {},
   "source": [
    "### 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "**a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.** <br>\n",
    "**b) Top 10 women’s ODI Batting players along with the records of their team and rating.**<br>\n",
    "**c) Top 10 women’s ODI all-rounder along with the records of their team and rating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303b8fd",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams in women’s cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "1ec9112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_name</th>\n",
       "      <th>matches</th>\n",
       "      <th>rating</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>28</td>\n",
       "      <td>167</td>\n",
       "      <td>4,663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>28</td>\n",
       "      <td>125</td>\n",
       "      <td>3,504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>29</td>\n",
       "      <td>118</td>\n",
       "      <td>3,425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>2,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>3,018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>2,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>78</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>26</td>\n",
       "      <td>67</td>\n",
       "      <td>1,753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_name matches rating points\n",
       "0      Australia      28    167  4,663\n",
       "1   South Africa      28    125  3,504\n",
       "2        England      29    118  3,425\n",
       "3          India      29    100  2,890\n",
       "4    New Zealand      31     97  3,018\n",
       "5    West Indies      28     89  2,478\n",
       "6     Bangladesh      12     78    935\n",
       "7       Pakistan      26     67  1,753\n",
       "8        Ireland       5     48    240\n",
       "9      Sri Lanka       5     47    233\n",
       "10      Zimbabwe       8      0      0"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def women_odi_cricket_team():\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    team_name = [name.next.next.next.next.text for name in soup.find_all('td', class_=\"table-body__cell rankings-table__team\")]\n",
    "    team_name.insert(0,soup.find_all('span', class_=\"flag-30 rankings-block__banner--flag AUS\")[0].next.next.text)\n",
    "\n",
    "    matches = [country_name.text for country_name in soup.find_all('td', class_=\"table-body__cell u-center-text\")][0::2]\n",
    "    matches.insert(0, soup.find('td', class_=\"rankings-block__banner--matches\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    points = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell u-center-text\")][1::2]\n",
    "    points.insert(0, soup.find('td', class_=\"rankings-block__banner--points\").text.replace('\\n', '').replace('  ', ''))\n",
    "\n",
    "    rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right rating\")]\n",
    "    rating.insert(0, soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n', '').replace('  ', ''))\n",
    "         \n",
    "    df_mens_odi = pd.DataFrame({'team_name':team_name, 'matches':matches, 'rating':rating, 'points':points})\n",
    "    return df_mens_odi\n",
    "\n",
    "#Enter value to check top playes\n",
    "women_odi_cricket_team()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8264732",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a1e72",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def8ca7",
   "metadata": {},
   "source": [
    "### b)Top 10 women’s ODI Batting players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "78c5c74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>career_best_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>740</td>\n",
       "      <td>741 v Australia, 22/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "      <td>734 v England, 03/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "      <td>834 v New Zealand, 24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>705</td>\n",
       "      <td>712 v India, 25/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>703</td>\n",
       "      <td>776 v India, 21/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>686</td>\n",
       "      <td>839 v Australia, 24/12/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>684</td>\n",
       "      <td>713 v West Indies, 15/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>682</td>\n",
       "      <td>791 v India, 27/06/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "      <td>756 v Australia, 02/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>669</td>\n",
       "      <td>797 v England, 28/02/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         player_name country rating             career_best_rating\n",
       "0    Laura Wolvaardt      SA    740    741 v Australia, 22/03/2022\n",
       "1        Beth Mooney     AUS    726      734 v England, 03/02/2022\n",
       "2        Meg Lanning     AUS    718  834 v New Zealand, 24/02/2016\n",
       "3     Natalie Sciver     ENG    705        712 v India, 25/02/2019\n",
       "4       Alyssa Healy     AUS    703        776 v India, 21/09/2021\n",
       "5        Mithali Raj     IND    686    839 v Australia, 24/12/2004\n",
       "6     Rachael Haynes     AUS    684  713 v West Indies, 15/03/2022\n",
       "7     Tammy Beaumont     ENG    682        791 v India, 27/06/2021\n",
       "8  Amy Satterthwaite      NZ    681    756 v Australia, 02/03/2017\n",
       "9    Smriti Mandhana     IND    669      797 v England, 28/02/2019"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------\n",
    "#same code is working for WOMEN ODI CRICKET\n",
    "#__________________________________________\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def women_odi_cricket(filter_result):\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    player_name = [name.text.replace('\\n', '') for name in soup.find_all('td', class_ =\"table-body__cell rankings-table__name name\")]\n",
    "    player_name.insert(0,soup.find('div', class_ =\"rankings-block__banner--name-large\").text)\n",
    "    \n",
    "    country = [country_name.text for country_name in soup.find_all('span', class_=\"table-body__logo-text\")]\n",
    "    country.insert(0, soup.find('div', class_ =\"rankings-block__banner--nationality\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    rating = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell rating\")]\n",
    "    rating.insert(0, soup.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    career_best_rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right u-hide-phablet\")]\n",
    "    career_best_rating.insert(0, soup.find('div',class_=\"rankings-block__career-best\").text.replace('\\n', '').replace('  ', ''))\n",
    "    \n",
    "    \n",
    "    df_mens_odi = pd.DataFrame({'player_name':player_name, 'country':country, 'rating':rating, 'career_best_rating':career_best_rating})\n",
    "    return df_mens_odi[df_mens_odi.index < filter_result]\n",
    "\n",
    "#Enter value to check top playes\n",
    "women_odi_cricket(filter_result = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c2c63",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b24c0",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664607d6",
   "metadata": {},
   "source": [
    "### c)Top 10 women’s ODI all-rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "ea047070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>career_best_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>404</td>\n",
       "      <td>548 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>376</td>\n",
       "      <td>391 v New Zealand, 16/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>359</td>\n",
       "      <td>419 v West Indies, 10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>340</td>\n",
       "      <td>365 v India, 12/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>335</td>\n",
       "      <td>339 v South Africa, 17/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>278</td>\n",
       "      <td>278 v Bangladesh, 25/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>249</td>\n",
       "      <td>397 v South Africa, 09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "      <td>308 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "      <td>296 v Australia, 03/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>217</td>\n",
       "      <td>308 v Australia, 02/02/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        player_name country rating              career_best_rating\n",
       "0      Ellyse Perry     AUS    404   548 v West Indies, 11/09/2019\n",
       "1    Natalie Sciver     ENG    376   391 v New Zealand, 16/09/2021\n",
       "2    Marizanne Kapp      SA    359   419 v West Indies, 10/09/2021\n",
       "3   Hayley Matthews      WI    340         365 v India, 12/03/2022\n",
       "4       Amelia Kerr      NZ    335  339 v South Africa, 17/03/2022\n",
       "5  Ashleigh Gardner     AUS    278    278 v Bangladesh, 25/03/2022\n",
       "6     Deepti Sharma     IND    249  397 v South Africa, 09/10/2019\n",
       "7     Jess Jonassen     AUS    246   308 v West Indies, 11/09/2019\n",
       "8   Katherine Brunt     ENG    239     296 v Australia, 03/02/2022\n",
       "9    Jhulan Goswami     IND    217     308 v Australia, 02/02/2016"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def women_odi_cricket(filter_result):\n",
    "    soup = BeautifulSoup(requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\").content)\n",
    "    \n",
    "    #list comprehension\n",
    "    player_name = [name.text.replace('\\n', '') for name in soup.find_all('td', class_ =\"table-body__cell rankings-table__name name\")]\n",
    "    player_name.insert(0,soup.find('div', class_ =\"rankings-block__banner--name-large\").text)\n",
    "    \n",
    "    country = [country_name.text for country_name in soup.find_all('span', class_=\"table-body__logo-text\")]\n",
    "    country.insert(0, soup.find('div', class_ =\"rankings-block__banner--nationality\").text.replace('\\n','').replace(' ', ''))\n",
    "    \n",
    "    rating = [ratings.text for ratings in soup.find_all('td', class_=\"table-body__cell rating\")]\n",
    "    rating.insert(0, soup.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    career_best_rating = [best_rating.text.replace('\\n','').replace('  ','') for best_rating in soup.find_all('td', class_ =\"table-body__cell u-text-right u-hide-phablet\")]\n",
    "    career_best_rating.insert(0, soup.find('div',class_=\"rankings-block__career-best\").text.replace('\\n', '').replace('  ', ''))\n",
    "    \n",
    "    \n",
    "    df_mens_odi = pd.DataFrame({'player_name':player_name, 'country':country, 'rating':rating, 'career_best_rating':career_best_rating})\n",
    "    return df_mens_odi[df_mens_odi.index < filter_result]\n",
    "\n",
    "#Enter value to check top playes\n",
    "women_odi_cricket(filter_result = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90aecb4",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871f45a",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4e91f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948729f3",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76b3ef",
   "metadata": {},
   "source": [
    "### 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890afd0",
   "metadata": {},
   "source": [
    "**CONTENT OF ALL 17 PAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "4837639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from page : 1\n",
      "Fetching data from page : 2\n",
      "Fetching data from page : 3\n",
      "Fetching data from page : 4\n",
      "Fetching data from page : 5\n",
      "Fetching data from page : 6\n",
      "Fetching data from page : 7\n",
      "Fetching data from page : 8\n",
      "Fetching data from page : 9\n",
      "Fetching data from page : 10\n",
      "Fetching data from page : 11\n",
      "Fetching data from page : 12\n",
      "Fetching data from page : 13\n",
      "Fetching data from page : 14\n",
      "Fetching data from page : 15\n",
      "Fetching data from page : 16\n",
      "Fetching data from page : 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>https://www.youtube.com/embed/z0gguhEmWiY?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>https://www.youtube.com/embed/_P7X8tMplsw?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>https://www.youtube.com/embed/fKl2JW_qrso?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>https://www.youtube.com/embed/IEEhzQoKtQU?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Quick Tip: Use a Wooden Pallet as a Lumber Rack</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>April 21, 2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>How to Record Sound From Your Computer’s Speak...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>March 2, 2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Ems and Rems for Sizing</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>September 21, 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>How to Build a Pergola</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>September 12, 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Adding Custom Web Fonts to Your Web Site Using...</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>July 1, 2013</td>\n",
       "      <td>https://www.youtube.com/embed/y2AlgMII1OU?vers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title         author  \\\n",
       "0    Python Tutorial: Zip Files – Creating and Extr...  Corey Schafer   \n",
       "1    Python Data Science Tutorial: Analyzing the 20...  Corey Schafer   \n",
       "2    Python Multiprocessing Tutorial: Run Code in P...  Corey Schafer   \n",
       "3    Python Threading Tutorial: Run Code Concurrent...  Corey Schafer   \n",
       "4                                  Update (2019-09-03)  Corey Schafer   \n",
       "..                                                 ...            ...   \n",
       "157    Quick Tip: Use a Wooden Pallet as a Lumber Rack  Corey Schafer   \n",
       "158  How to Record Sound From Your Computer’s Speak...  Corey Schafer   \n",
       "159                            Ems and Rems for Sizing  Corey Schafer   \n",
       "160                             How to Build a Pergola  Corey Schafer   \n",
       "161  Adding Custom Web Fonts to Your Web Site Using...  Corey Schafer   \n",
       "\n",
       "                   date                                               link  \n",
       "0     November 19, 2019  https://www.youtube.com/embed/z0gguhEmWiY?vers...  \n",
       "1      October 17, 2019  https://www.youtube.com/embed/_P7X8tMplsw?vers...  \n",
       "2    September 21, 2019  https://www.youtube.com/embed/fKl2JW_qrso?vers...  \n",
       "3    September 12, 2019  https://www.youtube.com/embed/IEEhzQoKtQU?vers...  \n",
       "4     September 3, 2019                                                NaN  \n",
       "..                  ...                                                ...  \n",
       "157      April 21, 2014                                                NaN  \n",
       "158       March 2, 2014                                                NaN  \n",
       "159  September 21, 2013                                                NaN  \n",
       "160  September 12, 2013                                                NaN  \n",
       "161        July 1, 2013  https://www.youtube.com/embed/y2AlgMII1OU?vers...  \n",
       "\n",
       "[162 rows x 4 columns]"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def coreyms_posts():\n",
    "    \n",
    "    url = 'https://coreyms.com/page/'\n",
    "    max_pages = [data.text for data in BeautifulSoup(requests.get('https://coreyms.com/page/1').content).find('div', class_=\"archive-pagination pagination\").find_all('li')][4]    \n",
    "    \n",
    "    title = []\n",
    "    author = []\n",
    "    date = []\n",
    "    content = []\n",
    "    link = []\n",
    "    \n",
    "    for page_number in range(1,int(max_pages)+1):\n",
    "        soup = BeautifulSoup(requests.get(url+str(page_number)).content)\n",
    "        containers = soup.find_all('article')        \n",
    "        print(f'Fetching data from page : {page_number}')\n",
    "        #TITLE\n",
    "        for data in containers:\n",
    "            title.append(data.find_all('h2')[0].text)\n",
    "        #AUTHOR\n",
    "        for data in containers:\n",
    "            author.append(data.find_all('a')[1].text)\n",
    "        #DATE\n",
    "        for data in containers:\n",
    "            date.append(data.find_all('time')[0].text) \n",
    "        #CONTENT\n",
    "        for data in containers:\n",
    "            content.append(data.find_all('p')[1].text)      \n",
    "        #YOUTUBE LINKS\n",
    "        for data in containers:\n",
    "            try:\n",
    "                link.append(data.find('iframe')['src'])\n",
    "                \n",
    "            except:\n",
    "                link.append(np.nan)\n",
    "                \n",
    "    df = pd.DataFrame({\"title\":title, \"author\":author, \"date\":date, \"link\":link})\n",
    "    \n",
    "    return df\n",
    "\n",
    "coreyms_posts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82457375",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39060337",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba3f1e",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2cae1",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f4a46",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48649a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde03baf",
   "metadata": {},
   "source": [
    "### 8) Write a python program to scrape house details from mentioned URL. It should include \n",
    "**1)House title \n",
    "2)location,\n",
    "3)Area,\n",
    "4)EMI \n",
    "5)price**<br>\n",
    "url = \"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "8c091501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_title</th>\n",
       "      <th>price</th>\n",
       "      <th>emi</th>\n",
       "      <th>area</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Raja...</td>\n",
       "      <td>₹1.1 Crores</td>\n",
       "      <td>₹63,045/MonthEstimated EMI</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>Independent House,  6th Cross road,9th main ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Tarang Parkway A...</td>\n",
       "      <td>₹1 Crore</td>\n",
       "      <td>₹57,314/MonthEstimated EMI</td>\n",
       "      <td>Basaveshwar Nagar</td>\n",
       "      <td>2nd Main Rd, Shivanagar, Basaveshwar Nagar, Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 BHK Flat  For Sale  In Kumar Ashraya Apartme...</td>\n",
       "      <td>₹66 Lacs</td>\n",
       "      <td>₹37,827/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Kumar Ashraya Apartments 194, 9th Cross Rd 2n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Brigade Gateway ...</td>\n",
       "      <td>₹2.62 Crores</td>\n",
       "      <td>₹1.5 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>Dr Rajkumar Road, Rajaji Nagar, Bengaluru, Kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Jaya...</td>\n",
       "      <td>₹3.85 Crores</td>\n",
       "      <td>₹2.21 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Independent House, TMC Layout behind rajalaxmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Blueberry Apartm...</td>\n",
       "      <td>₹1.53 Crores</td>\n",
       "      <td>₹87,691/MonthEstimated EMI</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>13th E Main Rd, Channakesahava Nagar, HAL 2nd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Mayitri Enclave ...</td>\n",
       "      <td>₹78 Lacs</td>\n",
       "      <td>₹44,705/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Mayitri Enclave, 39th C, 5T Block, 4th T Block...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Prak...</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "      <td>₹77,374/MonthEstimated EMI</td>\n",
       "      <td>Prakash Nagar, Rajaji Nagar</td>\n",
       "      <td>Independent House, 6th C cross 3rd main rd nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jains Prakruti, Jayan...</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>₹85,971/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar 7TH BLOCK</td>\n",
       "      <td>Kanakapura Road, Jayanagar, Bangalore, Karnata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Jayan...</td>\n",
       "      <td>₹2.7 Crores</td>\n",
       "      <td>₹1.55 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar 4th 'T' Block</td>\n",
       "      <td>Independent House, SBI Branch Jayanagar 9th bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3 BHK Flat  For Sale  In Benaka Apartments In ...</td>\n",
       "      <td>₹85 Lacs</td>\n",
       "      <td>₹48,717/MonthEstimated EMI</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Jains Prakriti I...</td>\n",
       "      <td>₹2 Crores</td>\n",
       "      <td>₹1.15 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Kanakapura Rd, 7th Block West, 7th Block, Jay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jayanagar Residency I...</td>\n",
       "      <td>₹1 Crore</td>\n",
       "      <td>₹57,314/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Jayanagar Residency, K V Layout, LIC Colony, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4 BHK Flat  For Sale  In Rrbc Piccassso In Jay...</td>\n",
       "      <td>₹6.83 Crores</td>\n",
       "      <td>₹3.91 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Municipal No.152, 18th main road, beside Sai B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4 BHK Flat  For Sale  In Phoenix  One Bangalor...</td>\n",
       "      <td>₹4.75 Crores</td>\n",
       "      <td>₹2.72 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Rajajinagar</td>\n",
       "      <td>Dr Rajkumar Rd, opposite Sheraton Hotel, Rajaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Laks...</td>\n",
       "      <td>₹1.1 Crores</td>\n",
       "      <td>₹63,045/MonthEstimated EMI</td>\n",
       "      <td>Lakshmipuram Indrinagar</td>\n",
       "      <td>Independent House, CMH Rd , Near B P Bakery4+ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3 BHK Flat  For Sale  In Rajaji Nagar</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "      <td>₹77,374/MonthEstimated EMI</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>Independent House, 242, 27th cross, 2nd Block,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3 BHK Flat  For Sale  In  Sgrr Pallavi Pristin...</td>\n",
       "      <td>₹1.3 Crores</td>\n",
       "      <td>₹74,508/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>11th Main Road,36 Cross, 4th T Block, Near ,Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 BHK Flat  For Sale  In Hal 2nd Stage,indiran...</td>\n",
       "      <td>₹3.7 Crores</td>\n",
       "      <td>₹2.12 Lacs/MonthEstimated EMI</td>\n",
       "      <td>HAL 2nd Stage,Indiranagar</td>\n",
       "      <td>Standalone building, 16th F main, Hal 2nd stag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Ashiana Gardens ...</td>\n",
       "      <td>₹1.4 Crores</td>\n",
       "      <td>₹80,240/MonthEstimated EMI</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>4, Sri Rama Temple Rd, Channakesahava Nagar, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4 BHK Flat  For Sale  In Golfridge In Indira N...</td>\n",
       "      <td>₹2.85 Crores</td>\n",
       "      <td>₹1.63 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Indira Nagar</td>\n",
       "      <td>embassy golf link road4 BHK Flat  For Sale  In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Raja...</td>\n",
       "      <td>₹1.46 Crores</td>\n",
       "      <td>₹83,679/MonthEstimated EMI</td>\n",
       "      <td>Rajajinagar</td>\n",
       "      <td>Independent House, 6th Cross Rd, 2nd Block  ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Jayan...</td>\n",
       "      <td>₹9.5 Crores</td>\n",
       "      <td>₹5.44 Lacs/MonthEstimated EMI</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Independent House, 47th Cross Rd, 8th Block, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2 BHK Flat  For Sale  In Aishwaryam Gokula In ...</td>\n",
       "      <td>₹78 Lacs</td>\n",
       "      <td>₹44,705/MonthEstimated EMI</td>\n",
       "      <td>Govindraja Nagar</td>\n",
       "      <td>1st main govindraja naagar blore 5600402 BHK F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Admiralty Manor,...</td>\n",
       "      <td>₹1.6 Crores</td>\n",
       "      <td>₹91,703/MonthEstimated EMI</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>Admiralty Manor, 6th Main Rd, Eshwara Layout, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          house_title         price  \\\n",
       "0   4+ BHK In Independent House  For Sale  In Raja...   ₹1.1 Crores   \n",
       "1   2 BHK Apartment  For Sale  In Tarang Parkway A...      ₹1 Crore   \n",
       "2   2 BHK Flat  For Sale  In Kumar Ashraya Apartme...      ₹66 Lacs   \n",
       "3   3 BHK Apartment  For Sale  In Brigade Gateway ...  ₹2.62 Crores   \n",
       "4   4+ BHK In Independent House  For Sale  In Jaya...  ₹3.85 Crores   \n",
       "5   2 BHK Apartment  For Sale  In Blueberry Apartm...  ₹1.53 Crores   \n",
       "6   3 BHK Apartment  For Sale  In Mayitri Enclave ...      ₹78 Lacs   \n",
       "7   4+ BHK In Independent House  For Sale  In Prak...  ₹1.35 Crores   \n",
       "8   2 BHK Flat  For Sale  In Jains Prakruti, Jayan...   ₹1.5 Crores   \n",
       "9   4 BHK In Independent House  For Sale  In Jayan...   ₹2.7 Crores   \n",
       "10  3 BHK Flat  For Sale  In Benaka Apartments In ...      ₹85 Lacs   \n",
       "11  2 BHK Apartment  For Sale  In Jains Prakriti I...     ₹2 Crores   \n",
       "12  2 BHK Flat  For Sale  In Jayanagar Residency I...      ₹1 Crore   \n",
       "13  4 BHK Flat  For Sale  In Rrbc Piccassso In Jay...  ₹6.83 Crores   \n",
       "14  4 BHK Flat  For Sale  In Phoenix  One Bangalor...  ₹4.75 Crores   \n",
       "15  4+ BHK In Independent House  For Sale  In Laks...   ₹1.1 Crores   \n",
       "16              3 BHK Flat  For Sale  In Rajaji Nagar  ₹1.35 Crores   \n",
       "17  3 BHK Flat  For Sale  In  Sgrr Pallavi Pristin...   ₹1.3 Crores   \n",
       "18  3 BHK Flat  For Sale  In Hal 2nd Stage,indiran...   ₹3.7 Crores   \n",
       "19  3 BHK Apartment  For Sale  In Ashiana Gardens ...   ₹1.4 Crores   \n",
       "20  4 BHK Flat  For Sale  In Golfridge In Indira N...  ₹2.85 Crores   \n",
       "21  4+ BHK In Independent House  For Sale  In Raja...  ₹1.46 Crores   \n",
       "22  4 BHK In Independent House  For Sale  In Jayan...   ₹9.5 Crores   \n",
       "23  2 BHK Flat  For Sale  In Aishwaryam Gokula In ...      ₹78 Lacs   \n",
       "24  3 BHK Apartment  For Sale  In Admiralty Manor,...   ₹1.6 Crores   \n",
       "\n",
       "                              emi                         area  \\\n",
       "0      ₹63,045/MonthEstimated EMI                 Rajaji Nagar   \n",
       "1      ₹57,314/MonthEstimated EMI            Basaveshwar Nagar   \n",
       "2      ₹37,827/MonthEstimated EMI                    Jayanagar   \n",
       "3    ₹1.5 Lacs/MonthEstimated EMI                 Rajaji Nagar   \n",
       "4   ₹2.21 Lacs/MonthEstimated EMI                    Jayanagar   \n",
       "5      ₹87,691/MonthEstimated EMI                  Indiranagar   \n",
       "6      ₹44,705/MonthEstimated EMI                    Jayanagar   \n",
       "7      ₹77,374/MonthEstimated EMI  Prakash Nagar, Rajaji Nagar   \n",
       "8      ₹85,971/MonthEstimated EMI          Jayanagar 7TH BLOCK   \n",
       "9   ₹1.55 Lacs/MonthEstimated EMI      Jayanagar 4th 'T' Block   \n",
       "10     ₹48,717/MonthEstimated EMI                  Indiranagar   \n",
       "11  ₹1.15 Lacs/MonthEstimated EMI                    Jayanagar   \n",
       "12     ₹57,314/MonthEstimated EMI                    Jayanagar   \n",
       "13  ₹3.91 Lacs/MonthEstimated EMI                    Jayanagar   \n",
       "14  ₹2.72 Lacs/MonthEstimated EMI                  Rajajinagar   \n",
       "15     ₹63,045/MonthEstimated EMI      Lakshmipuram Indrinagar   \n",
       "16     ₹77,374/MonthEstimated EMI                 Rajaji Nagar   \n",
       "17     ₹74,508/MonthEstimated EMI                    Jayanagar   \n",
       "18  ₹2.12 Lacs/MonthEstimated EMI  HAL 2nd Stage,Indiranagar     \n",
       "19     ₹80,240/MonthEstimated EMI                  Indiranagar   \n",
       "20  ₹1.63 Lacs/MonthEstimated EMI                 Indira Nagar   \n",
       "21     ₹83,679/MonthEstimated EMI                  Rajajinagar   \n",
       "22  ₹5.44 Lacs/MonthEstimated EMI                    Jayanagar   \n",
       "23     ₹44,705/MonthEstimated EMI             Govindraja Nagar   \n",
       "24     ₹91,703/MonthEstimated EMI                  Indiranagar   \n",
       "\n",
       "                                             location  \n",
       "0   Independent House,  6th Cross road,9th main ro...  \n",
       "1   2nd Main Rd, Shivanagar, Basaveshwar Nagar, Be...  \n",
       "2    Kumar Ashraya Apartments 194, 9th Cross Rd 2n...  \n",
       "3   Dr Rajkumar Road, Rajaji Nagar, Bengaluru, Kar...  \n",
       "4   Independent House, TMC Layout behind rajalaxmi...  \n",
       "5   13th E Main Rd, Channakesahava Nagar, HAL 2nd ...  \n",
       "6   Mayitri Enclave, 39th C, 5T Block, 4th T Block...  \n",
       "7   Independent House, 6th C cross 3rd main rd nea...  \n",
       "8   Kanakapura Road, Jayanagar, Bangalore, Karnata...  \n",
       "9   Independent House, SBI Branch Jayanagar 9th bl...  \n",
       "10  871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...  \n",
       "11   Kanakapura Rd, 7th Block West, 7th Block, Jay...  \n",
       "12  Jayanagar Residency, K V Layout, LIC Colony, J...  \n",
       "13  Municipal No.152, 18th main road, beside Sai B...  \n",
       "14  Dr Rajkumar Rd, opposite Sheraton Hotel, Rajaj...  \n",
       "15  Independent House, CMH Rd , Near B P Bakery4+ ...  \n",
       "16  Independent House, 242, 27th cross, 2nd Block,...  \n",
       "17  11th Main Road,36 Cross, 4th T Block, Near ,Po...  \n",
       "18  Standalone building, 16th F main, Hal 2nd stag...  \n",
       "19  4, Sri Rama Temple Rd, Channakesahava Nagar, H...  \n",
       "20  embassy golf link road4 BHK Flat  For Sale  In...  \n",
       "21  Independent House, 6th Cross Rd, 2nd Block  ne...  \n",
       "22  Independent House, 47th Cross Rd, 8th Block, 1...  \n",
       "23  1st main govindraja naagar blore 5600402 BHK F...  \n",
       "24  Admiralty Manor, 6th Main Rd, Eshwara Layout, ...  "
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def nobroker():\n",
    "    url = \"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar\"\n",
    "    soup = BeautifulSoup(requests.get(url).content)\n",
    "    containers = soup.find_all('article')\n",
    "    \n",
    "    house_title = [data.find_all('span')[0].text for data in containers]\n",
    "    price = [data.find_all('div', class_=\"font-semi-bold heading-6\")[2].text for data in containers]\n",
    "    emi = [data.find_all('div')[15].text for data in containers]\n",
    "    area = [data.find_all('span')[10].text for data in containers]\n",
    "    location = [data.find_all('span')[6].text for data in containers]\n",
    "\n",
    "    df = pd.DataFrame({\"house_title\":house_title, \"price\":price, \"emi\":emi, \"area\":area, \"location\":location})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "nobroker()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a7d13",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deac5a4",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4c2db",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02061b5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2237d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099a68d",
   "metadata": {},
   "source": [
    "## 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "**i) Restaurant name <br>\n",
    "ii) Cuisine<br>\n",
    "iii) Location<br>\n",
    "iv) Ratings<br>\n",
    "v) Image URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "86fbd77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>cuisin</th>\n",
       "      <th>location</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nostalgia</td>\n",
       "      <td>₹ 1,200 for 2 (approx)</td>\n",
       "      <td>Portuguese, Goan</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House No. 2</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Chinese, Continental, Goan, North Indian</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin's Place -The Village Bistro &amp; Pub</td>\n",
       "      <td>₹ 700 for 2 (approx)</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AJ's</td>\n",
       "      <td>₹ 600 for 2 (approx)</td>\n",
       "      <td>Continental, Fast Food, American, Pizza</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Navtara</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>Goan, North Indian, South Indian</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cremeux</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Fast Food, Italian, Desserts</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Navtara</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>Goan, North Indian, South Indian</td>\n",
       "      <td>Reliance Magnum,Majorda, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cremeux</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Desserts, Fast Food, Pizza</td>\n",
       "      <td>Navelim, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U.S Pizza</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Chocolate Room</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Beverages, Desserts, Fast Food, Italian</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Smokin' Joe's</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Beno</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Continental, Finger Food, Health Food, Europea...</td>\n",
       "      <td>Benaulim, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Farm house</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian, Fast Food</td>\n",
       "      <td>Benaulim, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tesouro</td>\n",
       "      <td>₹ 1,500 for 2 (approx)</td>\n",
       "      <td>European, Fast Food</td>\n",
       "      <td>Colva, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Charlie Chang's</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>Chinese, Thai</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cafe Signo</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>North Indian, Goan</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Egganbreak 24X7</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>North Indian, South Indian</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cavatina</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>Continental, Italian, Mexican</td>\n",
       "      <td>Benaulim, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Foodella Restaurant</td>\n",
       "      <td>₹ 600 for 2 (approx)</td>\n",
       "      <td>Chinese, Goan, Biryani</td>\n",
       "      <td>Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tavir</td>\n",
       "      <td>₹ 900 for 2 (approx)</td>\n",
       "      <td>North Indian, Fast Food</td>\n",
       "      <td>The Sapphire Comfort Hotel,Margao, South Goa</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title                   price  \\\n",
       "0                                  Nostalgia  ₹ 1,200 for 2 (approx)   \n",
       "1                                House No. 2    ₹ 800 for 2 (approx)   \n",
       "2   Martin's Place -The Village Bistro & Pub    ₹ 700 for 2 (approx)   \n",
       "3                                       AJ's    ₹ 600 for 2 (approx)   \n",
       "4                                    Navtara    ₹ 500 for 2 (approx)   \n",
       "5                                    Cremeux    ₹ 800 for 2 (approx)   \n",
       "6                                    Navtara    ₹ 500 for 2 (approx)   \n",
       "7                                    Cremeux    ₹ 800 for 2 (approx)   \n",
       "8                                  Pizza Hut    ₹ 800 for 2 (approx)   \n",
       "9                                  U.S Pizza    ₹ 500 for 2 (approx)   \n",
       "10                        The Chocolate Room    ₹ 800 for 2 (approx)   \n",
       "11                             Smokin' Joe's    ₹ 500 for 2 (approx)   \n",
       "12                                      Beno  ₹ 2,000 for 2 (approx)   \n",
       "13                            The Farm house    ₹ 800 for 2 (approx)   \n",
       "14                                   Tesouro  ₹ 1,500 for 2 (approx)   \n",
       "15                           Charlie Chang's    ₹ 800 for 2 (approx)   \n",
       "16                                Cafe Signo    ₹ 800 for 2 (approx)   \n",
       "17                           Egganbreak 24X7    ₹ 500 for 2 (approx)   \n",
       "18                                  Cavatina  ₹ 2,200 for 2 (approx)   \n",
       "19                       Foodella Restaurant    ₹ 600 for 2 (approx)   \n",
       "20                                     Tavir    ₹ 900 for 2 (approx)   \n",
       "\n",
       "                                               cuisin  \\\n",
       "0                                    Portuguese, Goan   \n",
       "1            Chinese, Continental, Goan, North Indian   \n",
       "2                                             Chinese   \n",
       "3             Continental, Fast Food, American, Pizza   \n",
       "4                    Goan, North Indian, South Indian   \n",
       "5                        Fast Food, Italian, Desserts   \n",
       "6                    Goan, North Indian, South Indian   \n",
       "7                          Desserts, Fast Food, Pizza   \n",
       "8                                    Pizza, Fast Food   \n",
       "9                                               Pizza   \n",
       "10            Beverages, Desserts, Fast Food, Italian   \n",
       "11                                   Pizza, Fast Food   \n",
       "12  Continental, Finger Food, Health Food, Europea...   \n",
       "13                   Chinese, North Indian, Fast Food   \n",
       "14                                European, Fast Food   \n",
       "15                                      Chinese, Thai   \n",
       "16                                 North Indian, Goan   \n",
       "17                         North Indian, South Indian   \n",
       "18                      Continental, Italian, Mexican   \n",
       "19                             Chinese, Goan, Biryani   \n",
       "20                            North Indian, Fast Food   \n",
       "\n",
       "                                        location  \\\n",
       "0                              Margao, South Goa   \n",
       "1                              Margao, South Goa   \n",
       "2                              Margao, South Goa   \n",
       "3                              Margao, South Goa   \n",
       "4                              Margao, South Goa   \n",
       "5                              Margao, South Goa   \n",
       "6             Reliance Magnum,Majorda, South Goa   \n",
       "7                             Navelim, South Goa   \n",
       "8                              Margao, South Goa   \n",
       "9                              Margao, South Goa   \n",
       "10                             Margao, South Goa   \n",
       "11                             Margao, South Goa   \n",
       "12                           Benaulim, South Goa   \n",
       "13                           Benaulim, South Goa   \n",
       "14                              Colva, South Goa   \n",
       "15                             Margao, South Goa   \n",
       "16                             Margao, South Goa   \n",
       "17                             Margao, South Goa   \n",
       "18                           Benaulim, South Goa   \n",
       "19                             Margao, South Goa   \n",
       "20  The Sapphire Comfort Hotel,Margao, South Goa   \n",
       "\n",
       "                                                image  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def dine_out():   \n",
    "    soup = BeautifulSoup(requests.get(\"https://www.dineout.co.in/goa-restaurants/welcome-back?p=1\").content)\n",
    "    containers = soup.find_all('div', class_ =\"restnt-main-wrap clearfix\")\n",
    "    \n",
    "    title = [data.find('a').text for data in containers]\n",
    "    cuisin = [data.find('span', class_ =\"double-line-ellipsis\").text.split('|')[1].lstrip() for data in containers]\n",
    "    price = [data.find('span', class_ =\"double-line-ellipsis\").find('span').text for data in containers]\n",
    "    location = [data.text for data in soup.find_all('div', class_ =\"restnt-loc ellipsis\")]\n",
    "    image_url = [data.find('img', class_=\"no-img\")['data-src'] for data in containers]\n",
    "\n",
    "    review_5 = [i.find('div', class_ =\"restnt-rating rating-5\") for i in containers]\n",
    "    review_4 = [i.find('div', class_ =\"restnt-rating rating-4\") for i in containers]\n",
    "    review_3 = [i.find('div', class_ =\"restnt-rating rating-3\") for i in containers]\n",
    "    review_2 = [i.find('div', class_ =\"restnt-rating rating-2\") for i in containers]\n",
    "    review_1 = [i.find('div', class_ =\"restnt-rating rating-1\") for i in containers]\n",
    "\n",
    "    review = []\n",
    "\n",
    "    for star5, star4, star3, star2, star1 in zip(review_5, review_4, review_3, review_2, review_1):\n",
    "        if star4 != None:\n",
    "            review.append(star4.text)\n",
    "        elif star5 != None:\n",
    "            review.append(star5.text)\n",
    "        elif star3 != None:\n",
    "            review.append(star3.text)\n",
    "        elif star2 != None:\n",
    "            review.append(star2.text)\n",
    "        elif star1 != None:\n",
    "            review.append(star1.text)\n",
    "        else:\n",
    "            review.append(np.nan)\n",
    "    \n",
    "    \n",
    "    df_dine_out = pd.DataFrame({'title':title, 'price':price, 'cuisin':cuisin, 'location':location, 'image':image_url})\n",
    "    return df_dine_out\n",
    "    \n",
    "dine_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4c1e9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb1b55",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f4568",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c48cd",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56b30a",
   "metadata": {},
   "source": [
    "## 10) Write a python program to scrape first 10 product details which include \n",
    "1)product name <br> 2)price <br> 3)Image URL**<br>\n",
    "https://www.bewakoof.com/women-printed-t-shirts  ------> this link is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "06f77dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "      <th>discount_eligibility</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women's Purple Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 479</td>\n",
       "      <td>₹459</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Grey Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 479</td>\n",
       "      <td>₹459</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women's Beige Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 491</td>\n",
       "      <td>₹469</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women's Grey Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 527</td>\n",
       "      <td>₹499</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women's Green Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 479</td>\n",
       "      <td>₹459</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Women's White Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 299</td>\n",
       "      <td>₹279</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Women's Beige Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 299</td>\n",
       "      <td>₹279</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Women's Yellow Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 527</td>\n",
       "      <td>₹499</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-yel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Women's Pink Colourblocked T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 575</td>\n",
       "      <td>₹549</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Women's Blue Typography T-shirt</td>\n",
       "      <td>1199</td>\n",
       "      <td>₹ 347</td>\n",
       "      <td>₹329</td>\n",
       "      <td>TriBe Members</td>\n",
       "      <td>https://images.bewakoof.com/t320/dillinger-blu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_name actual_price  price discount  \\\n",
       "0   Women's Purple Typography T-shirt         1199  ₹ 479     ₹459   \n",
       "1     Women's Grey Typography T-shirt         1199  ₹ 479     ₹459   \n",
       "2    Women's Beige Typography T-shirt         1199  ₹ 491     ₹469   \n",
       "3     Women's Grey Typography T-shirt         1199  ₹ 527     ₹499   \n",
       "4    Women's Green Typography T-shirt         1199  ₹ 479     ₹459   \n",
       "5    Women's White Typography T-shirt         1199  ₹ 299     ₹279   \n",
       "6    Women's Beige Typography T-shirt         1199  ₹ 299     ₹279   \n",
       "7   Women's Yellow Typography T-shirt         1199  ₹ 527     ₹499   \n",
       "8  Women's Pink Colourblocked T-shirt         1199  ₹ 575     ₹549   \n",
       "9     Women's Blue Typography T-shirt         1199  ₹ 347     ₹329   \n",
       "\n",
       "  discount_eligibility                                          image_url  \n",
       "0        TriBe Members  https://images.bewakoof.com/t320/dillinger-pur...  \n",
       "1        TriBe Members  https://images.bewakoof.com/t320/dillinger-gre...  \n",
       "2        TriBe Members  https://images.bewakoof.com/t320/dillinger-bei...  \n",
       "3        TriBe Members  https://images.bewakoof.com/t320/dillinger-gre...  \n",
       "4        TriBe Members  https://images.bewakoof.com/t320/dillinger-gre...  \n",
       "5        TriBe Members  https://images.bewakoof.com/t320/dillinger-whi...  \n",
       "6        TriBe Members  https://images.bewakoof.com/t320/dillinger-bei...  \n",
       "7        TriBe Members  https://images.bewakoof.com/t320/dillinger-yel...  \n",
       "8        TriBe Members  https://images.bewakoof.com/t320/dillinger-pin...  \n",
       "9        TriBe Members  https://images.bewakoof.com/t320/dillinger-blu...  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bewakoof():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get('https://www.bewakoof.com/women-printed-t-shirts').content)\n",
    "    containers = soup.find_all('a',class_=\"col-sm-4 col-xs-6\")\n",
    "    \n",
    "    product_name = [data.find_all('h3')[0].text for data in containers]\n",
    "    price  = [data.find_all('span', class_=\"discountedPriceText\")[0].text.replace('â‚¹ ','') for data in containers]\n",
    "    actual_price = [data.find_all('span', class_=\"actualPriceText\")[0].text for data in containers]\n",
    "    discount = [data.find('div', class_=\"loyaltyPriceBox\").find('b').text.replace('â‚¹','') for data in containers]\n",
    "    eligibility = [' '.join(data.find('div', class_=\"loyaltyPriceBox\").find('h6').text.split()[1:]) for data in containers]\n",
    "    image_url = [data.find('img')['src'] for data in containers]\n",
    "    \n",
    "    df = pd.DataFrame({\"product_name\":product_name,\"actual_price\":actual_price, \"price\":price, \"discount\":discount, \"discount_eligibility\":eligibility, \"image_url\":image_url})\n",
    "    return df\n",
    "\n",
    "bewakoof()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990942c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b872d",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
